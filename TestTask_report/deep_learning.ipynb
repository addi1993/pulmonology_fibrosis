{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/ilyas/anaconda/envs/KAMI/lib/python3.6/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import scipy\n",
    "import dicom\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 64, 64\n",
    "\n",
    "pathTrainNeg = \"./fibrosis_patches_8/train/norm\"\n",
    "pathTrainPos = \"./fibrosis_patches_8/train/path\"\n",
    "pathTestPos = \"./fibrosis_patches_8/test/path\"\n",
    "pathTestNeg = \"./fibrosis_patches_8/test/norm\"\n",
    "nb_train_samples = 10000\n",
    "nb_validation_samples = 5000\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kind of preprocessing and normalizing dicom images\n",
    "def load_and_normalize_dicom(path):\n",
    "    dicom1 = dicom.read_file(path)\n",
    "    dicom_img = dicom1.pixel_array.astype(np.float64)\n",
    "    mn = dicom_img.min()\n",
    "    mx = dicom_img.max()\n",
    "    \n",
    "    if (mx - mn) != 0:\n",
    "        dicom_img = (dicom_img - mn)/(mx-mn)\n",
    "    else:\n",
    "        dicom_img[:, :] = 0 \n",
    "    \n",
    "    return dicom_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstFilesTrainNeg = []\n",
    "lstFilesTrainPos = []\n",
    "lstFilesTestNeg = []\n",
    "lstFilesTestPos = []\n",
    "for dirName, subdirList, fileList in os.walk(pathTrainNeg):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():\n",
    "            lstFilesTrainNeg.append(os.path.join(dirName,filename))\n",
    "for dirName, subdirList, fileList in os.walk(pathTrainPos):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():\n",
    "            lstFilesTrainPos.append(os.path.join(dirName,filename))\n",
    "for dirName, subdirList, fileList in os.walk(pathTestPos):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():\n",
    "            lstFilesTestPos.append(os.path.join(dirName,filename))\n",
    "for dirName, subdirList, fileList in os.walk(pathTestNeg):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():\n",
    "            lstFilesTestNeg.append(os.path.join(dirName,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "for idx,img in enumerate(lstFilesTrainNeg):\n",
    "    X_train.append(load_and_normalize_dicom(img))\n",
    "    y_train.append(0)\n",
    "    if idx>nb_train_samples:\n",
    "        break\n",
    "\n",
    "for idx,img in enumerate(lstFilesTrainPos):\n",
    "    X_train.append(load_and_normalize_dicom(img))\n",
    "    y_train.append(1)\n",
    "    if idx>nb_train_samples:\n",
    "        break\n",
    "\n",
    "(X_train, y_train) = unison_shuffled_copies(np.asarray(X_train), np.asarray(y_train))\n",
    "X_train = np.asanyarray(X_train)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_width, img_height,1)\n",
    "for idx,img in enumerate(lstFilesTestNeg):\n",
    "    X_test.append(load_and_normalize_dicom(img))\n",
    "    y_test.append(0)\n",
    "    if idx>nb_validation_samples:\n",
    "        break\n",
    "for idx,img in enumerate(lstFilesTestPos):\n",
    "    X_test.append(load_and_normalize_dicom(img))\n",
    "    y_test.append(1)\n",
    "    if idx>nb_validation_samples:\n",
    "        break\n",
    "X_test = np.asanyarray(X_test)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_width, img_height,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19736 samples, validate on 5326 samples\n",
      "Epoch 1/10\n",
      "19736/19736 [==============================] - 87s - loss: 0.6734 - acc: 0.5851 - val_loss: 0.6626 - val_acc: 0.6127\n",
      "Epoch 2/10\n",
      "19736/19736 [==============================] - 93s - loss: 0.6365 - acc: 0.6408 - val_loss: 0.6041 - val_acc: 0.6857\n",
      "Epoch 3/10\n",
      "19736/19736 [==============================] - 85s - loss: 0.6081 - acc: 0.6653 - val_loss: 0.6039 - val_acc: 0.6444\n",
      "Epoch 4/10\n",
      "19736/19736 [==============================] - 88s - loss: 0.5883 - acc: 0.6847 - val_loss: 0.6270 - val_acc: 0.6596\n",
      "Epoch 5/10\n",
      "19736/19736 [==============================] - 85s - loss: 0.5732 - acc: 0.6963 - val_loss: 0.6226 - val_acc: 0.6036\n",
      "Epoch 6/10\n",
      "19736/19736 [==============================] - 87s - loss: 0.5672 - acc: 0.7010 - val_loss: 0.5835 - val_acc: 0.6782\n",
      "Epoch 7/10\n",
      "19736/19736 [==============================] - 87s - loss: 0.5579 - acc: 0.7055 - val_loss: 0.6058 - val_acc: 0.6327\n",
      "Epoch 8/10\n",
      "19736/19736 [==============================] - 82s - loss: 0.5519 - acc: 0.7116 - val_loss: 0.7013 - val_acc: 0.5986\n",
      "Epoch 9/10\n",
      "19736/19736 [==============================] - 77s - loss: 0.5466 - acc: 0.7169 - val_loss: 0.6176 - val_acc: 0.6250\n",
      "Epoch 10/10\n",
      "19736/19736 [==============================] - 89s - loss: 0.5396 - acc: 0.7183 - val_loss: 0.5881 - val_acc: 0.7073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129da3a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,  validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on 19736 samples, validate on 4004 samples\n",
    "Epoch 1/50\n",
    "19736/19736 [==============================] - 81s - loss: 0.6475 - acc: 0.6190 - val_loss: 0.5621 - val_acc: 0.7373\n",
    "Epoch 2/50\n",
    "19736/19736 [==============================] - 80s - loss: 0.5807 - acc: 0.6891 - val_loss: 0.5320 - val_acc: 0.7110\n",
    "Epoch 3/50\n",
    "19736/19736 [==============================] - 82s - loss: 0.5337 - acc: 0.7239 - val_loss: 0.5859 - val_acc: 0.6496\n",
    "Epoch 4/50\n",
    "19736/19736 [==============================] - 80s - loss: 0.4795 - acc: 0.7614 - val_loss: 0.7152 - val_acc: 0.5937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some paragraphs about augumentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "dest_path = os.path.dirname(os.path.realpath(\"./\")) + \"/augum_data/\"\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "x = load_and_normalize_dicom('fibrosis_patches_8/train/norm/1_1.dcm')\n",
    "x = x.reshape((1,)+x.shape+(1,))\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=dest_path, save_prefix='aug', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
